{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import nd2reader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from nd2reader import ND2Reader\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\1\\\\0\\\\10x_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\1\\\\0\\\\EPIFITC_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\1\\\\0\\\\EPIRedTracker_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\10x_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\10x_2.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIFITC_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIFITC_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIFITC_2.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIRedTracker_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIRedTracker_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\0\\\\EPIRedTracker_2.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\10x_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\10x_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\EPIFITC _1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\EPIFITC_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\EPIRedTracker_0.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiff\\\\EPIRedTracker_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiif1\\\\10x_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiif1\\\\EPIFITC_1.tif', 'C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\\\\2\\\\1\\\\stiif1\\\\EPIRedTracker_1.tif']\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob(os.path.join(\"C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/241104\", \"**\",\"*.tif\"),recursive=True)\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving (img, field, i_path):\n",
    "    img_res = cv2.resize(img, (800, 600))\n",
    "    base_name = os.path.splitext(os.path.basename(i_path))[0]\n",
    "    parts = base_name.split('_')\n",
    "\n",
    "    output_subdir = os.path.join('C:/Users/srboval1/OneDrive - Aalto University/Collab/Ivaska_collab/Viability/', f\"{parts[0]}\")\n",
    "    os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    " #   saving(img, i_path)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluorescent images - no z-projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_channel(channel):\n",
    "    channel_index = None  \n",
    "    if channel == 'EPIRedTracker':\n",
    "        channel_index = 0\n",
    "    elif channel == 'EPIFITC':\n",
    "        channel_index = 1\n",
    "    elif channel == '10x':\n",
    "        channel_index = 2\n",
    "    \n",
    "    return channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_list = []\n",
    "\n",
    "for count, i in enumerate(paths):\n",
    "    image = cv2.imread(i) #reads the image into a NumPy array.\n",
    "    parts = os.path.splitext(os.path.basename(i))[0].split('_')\n",
    "    channel = parts[0]\n",
    "    partss = (i.split(\"/\")[7]).split(\"\\\\\")\n",
    "    holder = (partss[1])\n",
    "    gradient = (partss[2])\n",
    "\n",
    "    channel_index = color_channel(channel)\n",
    "    running_id = parts[1]\n",
    "        \n",
    "    image_info = {\n",
    "        'holder': holder,\n",
    "        'gradient': gradient,\n",
    "        'running_id': running_id,  \n",
    "        'channel_index': channel_index,\n",
    "        'image': image  # Optionally, store the image array\n",
    "    }\n",
    "    image_data_list.append(image_info)\n",
    "\n",
    "grouped_data = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in image_data_list:\n",
    "    holder = item['holder']\n",
    "    gradient = item['gradient']\n",
    "    running_id = item['running_id']\n",
    "    channel_index = item['channel_index']\n",
    "    image = item['image']\n",
    "    \n",
    "    # Create a dictionary for each item\n",
    "    image_info = {\n",
    "        'holder': holder,\n",
    "        'gradient': gradient,\n",
    "        'running_id': running_id,\n",
    "        'channel_index': channel_index,\n",
    "        'image': image\n",
    "    }\n",
    "    \n",
    "    # Append the item to the appropriate group\n",
    "grouped_data[holder][gradient][running_id][channel_index].append({\n",
    "        'image': image\n",
    "    })\n",
    "# Convert to a regular dictionary for easier inspection (optional)\n",
    "grouped_data = dict(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holder: 1\n",
      "  Gradient: 0\n",
      "  Running_id: 1\n",
      "Holder: 2\n",
      "  Gradient: 0\n",
      "  Running_id: 0\n",
      "  Running_id: 2\n",
      "  Running_id: 1\n",
      "  Gradient: 1\n",
      "  Running_id: 0\n",
      "  Running_id: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "# Grouping data structure\n",
    "grouped_data = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "\n",
    "# Loop through each item in the list\n",
    "for item in image_data_list:\n",
    "    holder = item['holder']\n",
    "    gradient = item['gradient']\n",
    "    running_id = item['running_id']\n",
    "    channel_index = item['channel_index']\n",
    "    image = item['image']\n",
    "\n",
    "    # Append the item to the appropriate group\n",
    "    grouped_data[holder][gradient][running_id][channel_index].append({\n",
    "        'image': image\n",
    "    })\n",
    "\n",
    "# Convert to a regular dictionary for easier inspection (optional)\n",
    "grouped_data = dict(grouped_data)\n",
    "\n",
    "def create_overlay(channels, target_size=(2304, 2304)):\n",
    "    num_channels = len(channels)\n",
    "    weights = 1.0 / num_channels\n",
    "    \n",
    "    overlay = None\n",
    "    x=0\n",
    "    for channel_index, images in channels.items():\n",
    "        for image_dict in images:\n",
    "            image = image_dict['image']\n",
    "            image_resized = cv2.resize(image, target_size)  # Resize to target size\n",
    "\n",
    "            # Initialize the overlay with the target size if it's the first image\n",
    "            if overlay is None:\n",
    "                overlay = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)  # Initialize overlay as a 3-channel image\n",
    "\n",
    "            if channel_index == '10x':  # Handle brightfield separately\n",
    "                # Normalize and convert the brightfield image to a color representation\n",
    "                brightfield_image_colored = cv2.applyColorMap(image, cv2.COLORMAP_JET)  # Using a colormap for visibility\n",
    "                overlay = cv2.addWeighted(overlay, 1, brightfield_image_colored, 0.5, 0) \n",
    "            #Colorizing image\n",
    "            else:\n",
    "                channel_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8) #empty image with 3 channels, all pixels are 0 and so it is black\n",
    "                channel_image[:, :, channel_index] = image_resized[:, :, channel_index]  # Place grayscale image into the specified channel\n",
    "            #channel_image no has color information in one of its RGB channels\n",
    "            \n",
    "                overlay = cv2.addWeighted(overlay, 1, channel_image, 1, 0)\n",
    "            x+=1\n",
    "    return overlay\n",
    "\n",
    "# Display the grouped data\n",
    "for holder, gradients in grouped_data.items():\n",
    "    print(f\"Holder: {holder}\")\n",
    "    for gradient, running_ids in gradients.items():\n",
    "        print(f\"  Gradient: {gradient}\")\n",
    "        for running_id, channels in running_ids.items():\n",
    "            print(f\"  Running_id: {running_id}\")\n",
    "            \n",
    "            overlay = create_overlay(channels)  # Extract images for overlay\n",
    "            \n",
    "            if overlay is not None:\n",
    "                resized_overlay = cv2.resize(overlay, (600, 700))  # Resize for display\n",
    "                cv2.imshow(f'Overlay for {holder} - {gradient} - Running ID {running_id}', resized_overlay)\n",
    "                cv2.waitKey(0)  # Wait for a key press\n",
    "                cv2.destroyAllWindows()  # Close the current window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holder: 1\n",
      "  Gradient: 0\n",
      "  Running_id: 1\n",
      "Holder: 2\n",
      "  Gradient: 0\n",
      "  Running_id: 0\n",
      "  Running_id: 2\n",
      "  Running_id: 1\n",
      "  Gradient: 1\n",
      "  Running_id: 0\n",
      "  Running_id: 1\n"
     ]
    }
   ],
   "source": [
    "grouped_data = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "\n",
    "# Loop through each item in the list\n",
    "for item in image_data_list:\n",
    "    holder = item['holder']\n",
    "    gradient = item['gradient']\n",
    "    running_id = item['running_id']\n",
    "    channel_index = item['channel_index']\n",
    "    image = item['image']\n",
    "\n",
    "    # Append the item to the appropriate group\n",
    "    grouped_data[holder][gradient][running_id][channel_index].append({\n",
    "        'image': image\n",
    "    })\n",
    "\n",
    "# Convert to a regular dictionary for easier inspection (optional)\n",
    "grouped_data = dict(grouped_data)\n",
    "\n",
    "def create_overlay(channels, target_size=(2304, 2304)):\n",
    "    num_channels = len(channels)\n",
    "    weights = 1.0 / num_channels\n",
    "    \n",
    "    overlay= None\n",
    "    \n",
    "    x = 0\n",
    "    for channel_index, images in channels.items():\n",
    "        for image_dict in images:\n",
    "            image= image_dict['image']\n",
    "            image_resized = cv2.resize(image, target_size)\n",
    "\n",
    "            if x == 0:\n",
    "                height, width = image.shape[:2]\n",
    "            \n",
    "            if overlay is None:\n",
    "                overlay = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "            if channel_index == '10x':  # Handle brightfield separately\n",
    "                # Normalize and convert the brightfield image to a color representation\n",
    "                brightfield_image_colored = cv2.applyColorMap(image, cv2.COLORMAP_JET)  # Using a colormap for visibility\n",
    "                overlay = cv2.addWeighted(overlay, 1, brightfield_image_colored, 0.5, 0) \n",
    "            #Colorizing image\n",
    "            else:\n",
    "                channel_image = np.zeros((height, width, 3), dtype=np.uint8) #empty image with 3 channels, all pixels are 0 and so it is black\n",
    "                channel_image[:, :, channel_index] = image_resized[:, :, channel_index]  # Place grayscale image into the specified channel\n",
    "            #channel_image no has color information in one of its RGB channels\n",
    "            \n",
    "                overlay = cv2.addWeighted(overlay, 1, channel_image, 1, 0)\n",
    "            x+=1\n",
    "    return overlay\n",
    "\n",
    "# Display the grouped data\n",
    "for holder, gradients in grouped_data.items():\n",
    "    print(f\"Holder: {holder}\")\n",
    "    for gradient, running_ids in gradients.items():\n",
    "        print(f\"  Gradient: {gradient}\")\n",
    "        for running_id, channels in running_ids.items():\n",
    "            print(f\"  Running_id: {running_id}\")\n",
    "            \n",
    "            overlay = create_overlay(channels)  # Extract images for overlay\n",
    "            \n",
    "            if overlay is not None:\n",
    "                resized_overlay = cv2.resize(overlay, (600, 700))\n",
    "\n",
    "                cv2.imshow(f'Overlay for {holder} - {gradient} - Running ID {running_id}', resized_overlay)\n",
    "                cv2.waitKey(0)  # Wait for a key press\n",
    "                cv2.destroyAllWindows()  # Close the current window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluorescent images with max z-projection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
